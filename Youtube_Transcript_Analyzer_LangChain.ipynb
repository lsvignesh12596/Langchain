{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Youtube Transcript Analyzer"
      ],
      "metadata": {
        "id": "GIduuflF2Avs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install python-dotenv\n",
        "!pip install youtube-transcript-api\n",
        "!pip install tiktoken\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "pqtIAEII3Sht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from dotenv import find_dotenv, load_dotenv\n",
        "from langchain.prompts.chat import(\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "s8Zw7TTn2Dhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"\""
      ],
      "metadata": {
        "id": "RXhkiqpA4AWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv(find_dotenv())\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "Sz6vKxO83TRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_db_from_yt_url(url):\n",
        "    loader = YoutubeLoader.from_youtube_url(url)\n",
        "    transcript = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=100)\n",
        "    docs = text_splitter.split_documents(transcript)\n",
        "\n",
        "    db = FAISS.from_documents(docs, embeddings)\n",
        "    return db"
      ],
      "metadata": {
        "id": "xYq2eU334eJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response_from_query(db, query, k=4):\n",
        "  \"\"\"\n",
        "  gpt-3.5-turbo can handle upto 4097 tokens. \n",
        "  Setting the chunk size to 1000 and k = 4 maximizes\n",
        "  the number of tokens to analyze\n",
        "  \"\"\"\n",
        "\n",
        "  docs = db.similarity_search(query, k=k)\n",
        "  docs_page_content = \" \".join([d.page_content for d in docs])\n",
        "\n",
        "  chat = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature = 0.2)\n",
        "\n",
        "  # Template to use for the system message prompt\n",
        "  template = \"\"\"\n",
        "  You are a helpful assistant that can answer questions about youtube videos\n",
        "  based on the video's transcript : {docs}\n",
        "\n",
        "  Only use the factual information from the transcript to answer the question.\n",
        "\n",
        "  If you feel there isn't enough information to answer the question, say \"I do not have answer to this question\".\n",
        "\n",
        "  Your answer should be verbose and detailed.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  sys_msg_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "  # human question prompt\n",
        "  human_template = \"Answer the following question: {question}\"\n",
        "  human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "  chat_prompt = ChatPromptTemplate.from_messages(\n",
        "      [sys_msg_prompt, human_message_prompt]\n",
        "  )\n",
        "\n",
        "  chain = LLMChain(llm=chat, prompt = chat_prompt)\n",
        "\n",
        "  response = chain.run(question = query, docs = docs_page_content)\n",
        "  response = response.replace(\"\\n\", \"\")\n",
        "  return response, docs"
      ],
      "metadata": {
        "id": "Zs1ZbhtR5Cvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_url = \"https://www.youtube.com/watch?v=L_Guz73e6fw\"\n",
        "db = create_db_from_yt_url(video_url)"
      ],
      "metadata": {
        "id": "pSEV0elS36-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are they saying about AGI?\"\n",
        "response, docs = get_response_from_query(db, query)\n",
        "print(textwrap.fill(response, width = 85))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwfUJMwQ9e_G",
        "outputId": "1038599f-92a6-4405-90d6-08dea25ff164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the given transcript, there are several discussions about AGI (Artificial General\n",
            "Intelligence). Sam Altman, the CEO of OpenAI, talks about the challenges they face\n",
            "while working on AGI and how they believe in the approach of iterative deployment and\n",
            "iterative discovery. He also mentions that the pace of progress is fast, and they are\n",
            "making good progress. When asked about what they would do if an AGI told them that\n",
            "aliens are already here, Sam Altman says that he would just go about his life. He\n",
            "further adds that the source of joy and happiness in life is from other humans, so\n",
            "mostly nothing would change unless it causes some kind of threat. Sam Altman also\n",
            "talks about how they were misunderstood and mocked when they announced that they were\n",
            "going to work on AGI in 2015. However, they don't get mocked as much now. He also\n",
            "mentions that he thought building AI would be the coolest thing ever, but he never\n",
            "thought he would get the chance to work on AGI. In summary, the transcript discusses\n",
            "the challenges and progress of working on AGI, the approach of iterative deployment\n",
            "and iterative discovery, and the initial skepticism and mockery faced by OpenAI when\n",
            "they announced their work on AGI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is the host of this program?\"\n",
        "response, docs = get_response_from_query(db, query)\n",
        "print(textwrap.fill(response, width = 85))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3IErIE291O5",
        "outputId": "eff59538-3c4c-4cef-97fe-8c842f97127a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The host of this program is not explicitly mentioned in the given transcript.\n",
            "However, based on the information provided, we can assume that the program is a\n",
            "podcast and the host interviews Sam Altman. The name of the host is not mentioned in\n",
            "this particular section of the transcript.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who are the hosts of this podcast?\"\n",
        "response, docs = get_response_from_query(db, query)\n",
        "print(textwrap.fill(response, width = 85))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3LwQF4z92MR",
        "outputId": "8e7bbfa1-7f32-44f4-f9a0-1738ebf46dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The transcript does not provide clear information about who the hosts of this podcast\n",
            "are. However, it does mention a conversation with Sam Altman and an interview with\n",
            "Lex Fridman. It is possible that one or both of them are the hosts, but this cannot\n",
            "be confirmed with certainty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Is this a podcast or an informative video with visuals?\"\n",
        "response, docs = get_response_from_query(db, query)\n",
        "print(textwrap.fill(response, width = 85))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Uk1e-7AbqW",
        "outputId": "07243e37-04ce-4aae-883a-1fba88900990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the transcript, it is not explicitly stated whether this is a podcast or an\n",
            "informative video with visuals. However, it is mentioned that this is the \"Lex\n",
            "Fridman podcast\" and there is a mention of \"listening to this conversation with Sam\n",
            "Altman.\" Therefore, it is likely that this is a podcast.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Can you summarize the entire podcast?\"\n",
        "response, docs = get_response_from_query(db, query)\n",
        "print(textwrap.fill(response, width = 85))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xvYb2-BAm0T",
        "outputId": "3d1f471e-7978-4bb7-b98d-6ab63e17314d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI language model, I cannot listen to the entire podcast, but based on the\n",
            "transcript provided, the podcast features a conversation between Lex Fridman and Sam\n",
            "Altman. They discuss various topics related to artificial intelligence, including the\n",
            "development of GPT4, the potential risks and benefits of AI, and the role of AI in\n",
            "society. They also touch on personal topics such as success, leadership, and the\n",
            "recent controversy surrounding Silicon Valley Bank. Overall, the podcast provides\n",
            "insights into the current state and future of AI, as well as the perspectives of a\n",
            "prominent figure in the tech industry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmGaguRDAvhj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}